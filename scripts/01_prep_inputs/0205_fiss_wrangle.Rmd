---
title: "0205_extract_inputs"
date: "Created: 2024-06-20 | Updated: `r format(Sys.Date(), '%Y-%m-%d')`"
output: 
  html_document:
    code_folding: "hide"
editor_options: 
  chunk_output_type: console
---

# Purpose of this script

Add columns to `form_fiss_site_2024` and then burn back a geopackage. 

```{r paths}
# path to raw form_fiss_site after QA
path_form_fiss_site_raw <- fs::path_expand(fs::path('~/Projects/gis/', params$gis_project_name ,'/data_field/2024/form_fiss_site_2024_raw.gpkg'))

#NEW geopcackage path for the form after we have added columns as per this script
path_form_fiss_site <- fs::path_expand(fs::path('~/Projects/gis/', params$gis_project_name ,'/data_field/2024/form_fiss_site_2024.gpkg'))
```



## Backup the form after the QA

```{r backup-raw}

t <- fs::path_expand(fs::path('~/Projects/repo/', params$repo_name ,'/data/backup/'))

form_fiss_site <- fpr::fpr_sp_gpkg_backup(
  path_gpkg = path_form_fiss_site_raw,
  dir_backup = fs::path_expand(fs::path('~/Projects/repo/', params$repo_name ,'/data/backup/')), #need to specify root directory if we want to render this script form the tables.R script, or else it makes another data/backup folder inside the directory this script is stored in (01_prep_inputs)
  update_utm = TRUE,
  update_site_id = FALSE,
  write_back_to_path = FALSE,
  return_object = TRUE,
  col_easting = "utm_easting",
  col_northing = "utm_northing"
) 
```


## Fix times

This is not always applicable and we will hopefully have a permanent fix soon.

For Skeena 2024 - Some of the the times in `form_pscis_2024` are incorrect in the form and are in PDT - so when read into R they get converted to UTC and are wrong... ugh times. 


```{r time-fix, eval T}

form_fiss_site_time_fix <-  form_fiss_site |> 
 dplyr::mutate(date_time_start_raw = date_time_start) |> 
 dplyr::mutate(date_time_start = dplyr::case_when(time_correct == FALSE ~ lubridate::force_tz(date_time_start_raw, tzone = "UTC"), TRUE ~ date_time_start_raw),
               date_time_start = dplyr::case_when(time_correct == FALSE ~ lubridate::with_tz(date_time_start, tzone = "America/Vancouver"), TRUE ~ date_time_start_raw)) |> 
  dplyr::relocate(date_time_start_raw, .before = date_time_start)


form_fiss_site <- form_fiss_site_time_fix |> 
  dplyr::select(-date_time_start_raw)

```


## Clean up the form 

```{r clean-form}
# clean up the form
form_fiss_site_cleaned <- form_fiss_site |> 
  # split the local_name into the site, location, and ef
  tidyr::separate(local_name, into = c("site", "location", "ef"), remove = FALSE) |> 
  dplyr::mutate(local_name = stringr::str_trim(local_name)) |> 
  # split out the date and the time - change type of column first
  dplyr::mutate(date_time_start = lubridate::ymd_hms(date_time_start, tz = "America/Vancouver"),
                date_time_start = lubridate::floor_date(date_time_start, unit = "second"),  # Remove microseconds
                survey_date = lubridate::date(date_time_start),
                time = hms::as_hms(date_time_start), 
                # Fix some vocabulary. Change "trib" to long version "Tributary" etc.
                gazetted_names = stringr::str_replace_all(gazetted_names, 'Trib ', 'Tributary '),
                crew_members = toupper(crew_members),
                # fill in text columns from spreadsheet that will likely never change
                waterbody_type = 'stream',
                method_for_utm = 'GPS general',
                method_for_channel_width = 'metre tape',
                method_for_wetted_width = 'metre tape',
                method_for_residual_pool_depth = 'metre stick',
                method_for_bankfull_depth = 'metre stick',
                method_for_gradient = 'clinometer',
                method_for_temperature = 'recording meter',
                method_for_conductivity = 'recording meter',
                method_for_p_h = 'pH meter (general)') |> 
  # arrange by surveyor and date/time
  dplyr::arrange(mergin_user, date_time_start) |> 
  # ditch the time since we don't need anymore. Time was dropped on gpkg creation due to type conflict
  dplyr::select(-time) |>
  # rearrange the columns for easier QA in QGIS.
  dplyr::select(
    date_time_start,
    local_name,
    gazetted_names,
    crew_members,
    comments,
    everything()) |> 
  dplyr::arrange(date_time_start)

```




## Query database to get 1:50,000 watershed codes
Really kind of humorous that we are getting 1:50,000 watershed codes from the database then the province turns around
and converts them back to 1:20,000 (pers. comm. Dave McEwan - Fisheries Standards Biologist - 778 698-4010 - Dave.McEwan@gov.bc.ca).

```{r get-wsc}

ids <- form_fiss_site_cleaned |> 
  dplyr::distinct(site) |> 
  dplyr::pull(site)

wscodes_raw <- fpr::fpr_db_query(
  query = glue::glue("
    SELECT DISTINCT ON (a.stream_crossing_id)
      a.stream_crossing_id,
      a.linear_feature_id,
      a.watershed_group_code,
      b.watershed_code_50k,
      b.blue_line_key_20k,
      b.watershed_key_20k,
      b.blue_line_key_50k,
      b.watershed_key_50k,
      b.match_type
    FROM bcfishpass.crossings_vw a
    LEFT OUTER JOIN whse_basemapping.fwa_streams_20k_50k b
      ON a.linear_feature_id = b.linear_feature_id_20k
    WHERE a.stream_crossing_id IN ({glue::glue_collapse(glue::single_quote(ids), sep = ', ')})
    ORDER BY a.stream_crossing_id, b.match_type;
  ")
)


parse_ws_code <- function(code) {
  dplyr::case_when(
    stringr::str_length(code) < 45 ~ NA_character_,
    TRUE ~ stringr::str_c(
      stringr::str_sub(code, 1, 3), "-",  stringr::str_sub(code, 4, 9), "-",  stringr::str_sub(code, 10, 14), "-",
      stringr::str_sub(code, 15, 19), "-", stringr::str_sub(code, 20, 23), "-", stringr::str_sub(code, 24, 27), "-",
      stringr::str_sub(code, 28, 30), "-", stringr::str_sub(code, 31, 33), "-", stringr::str_sub(code, 34, 36), "-",
      stringr::str_sub(code, 37, 39), "-", stringr::str_sub(code, 40, 42), "-", stringr::str_sub(code, 43, 45)
    )
  )
}


wscodes <- wscodes_raw |>
  dplyr::filter(stringr::str_length(watershed_code_50k) == 45) |>
  dplyr::mutate(watershed_code_50k_parsed = parse_ws_code(watershed_code_50k))



# 160-635400-46400-00000-0000-0000-000-000-000-000-000-000
```


```{rget-wsc-hack, eval = F}

##### HACK FOR IF WE CANT USE bcfishpass.crossings_vw FROM BCFISHPASS #####

# this was a work around for this issue here https://github.com/NewGraphEnvironment/fish_passage_peace_2024_reporting/issues/7. 

# use the bcfishpass.crossings_vw layer form the sern_peace_fwcp_2023 GIS project
crossings_vw <- sf::st_read(dsn = '/Users/lucyschick/Projects/gis/sern_peace_fwcp_2023/background_layers.gpkg',
                       layer = 'bcfishpass.crossings_vw') |> 
  sf::st_drop_geometry() |> 
  dplyr::filter(stream_crossing_id %in% ids)


fwa_streams <- fpr::fpr_db_query(query = glue::glue("
  SELECT DISTINCT ON (linear_feature_id_20k)
    linear_feature_id_20k,
    watershed_code_50k,
    blue_line_key_20k,
    watershed_key_20k,
    blue_line_key_50k,
    watershed_key_50k,
    match_type
  FROM whse_basemapping.fwa_streams_20k_50k
  WHERE linear_feature_id_20k IN ({glue::glue_collapse(glue::single_quote(crossings_vw$linear_feature_id), sep = ', ')})
  ORDER BY linear_feature_id_20k, match_type
"))

wscodes <- crossings_vw |>
  left_join(fwa_streams, by = c("linear_feature_id" = "linear_feature_id_20k")) |>
  mutate(
    watershed_code_50k_parsed = paste(
      substring(watershed_code_50k, 1, 3),    # First 3 digits
      substring(watershed_code_50k, 4, 9),   # Next 6 digits
      substring(watershed_code_50k, 10, 14), # Next 5 digits
      substring(watershed_code_50k, 15, 19), # Next 5 digits
      substring(watershed_code_50k, 20, 24), # Next 5 digits
      substring(watershed_code_50k, 25, 29), # Next 5 digits
      substring(watershed_code_50k, 30, 34), # Next 5 digits
      substring(watershed_code_50k, 35, 39), # Next 5 digits
      substring(watershed_code_50k, 40, 44), # Next 5 digits
      substring(watershed_code_50k, 45, 49), # Next 5 digits
      sep = "-"
    )
  ) |>
  select(
    stream_crossing_id,
    linear_feature_id,
    watershed_group_code,
    watershed_code_50k,
    watershed_code_50k_parsed,
    blue_line_key_20k,
    watershed_key_20k,
    blue_line_key_50k,
    watershed_key_50k,
    match_type
  )

##### END HACK #####
```


We need to QA the watershed codes using the `whse_fish.wdic_waterbody_route_line_svw` layer.  This layer has now been added the 2023 QGIS shared projects for Skeena and Peace. QAed and all are correct.

Finally, lets join it to the form_fiss_site so we can copy/paste it into the spreadsheet all at once.

```{r wsc-join}

## join watershed codes to form_fiss_site
form_fiss_site_prep2 <- dplyr::left_join(
  form_fiss_site_cleaned |> 
    dplyr::mutate(site = as.integer(site)),
  
  wscodes |> 
    dplyr::select(stream_crossing_id, watershed_code_50k = watershed_code_50k_parsed, watershed_group_code),
  
  by = c('site' = 'stream_crossing_id')) |> 
  
  dplyr::mutate(waterbody_id = paste0('00000', watershed_group_code),
                waterbody_type = 'stream')
```



## Calculate the average of the numeric columns

```{r calculate-averages}

# aggregate the numeric columns
# as per the example in ?ngr_str_df_col_agg
col_str_negate = "time|method|avg|average"
col_str_to_agg <- c("channel_width", "wetted_width", "residual_pool", "gradient", "bankfull_depth")
columns_result <- c("avg_channel_width_m", "avg_wetted_width_m", "average_residual_pool_depth_m", "average_gradient_percent", "average_bankfull_depth_m")

form_fiss_site_prep3 <- purrr::reduce(
  .x = seq_along(col_str_to_agg),
  .f = function(dat_acc, i) {
    ngr::ngr_str_df_col_agg(
      # we call the dataframe that accumulates results dat_acc
      dat = dat_acc,
      col_str_match = col_str_to_agg[i],
      col_result = columns_result[i],
      col_str_negate = col_str_negate,
      decimal_places = 1
    )
  },
  .init = form_fiss_site_prep2
)
```


## Burn back to the geopackage
Burn back to geopackage so all the new columns/data are also in the form

```{r fiss-burn-gpkg}
form_fiss_site_prep3 |> 
  sf::st_write(dsn = path_form_fiss_site,
               append = FALSE,
               delete_dsn = TRUE)

```


## Backup the new complete form 

```{r backup-complete}

fpr::fpr_sp_gpkg_backup(
  path_gpkg = path_form_fiss_site,
  dir_backup = fs::path_expand(fs::path('~/Projects/repo/', repo_name ,'/data/backup/')), #need to specify root directory if we want to render this     script form the tables.R script, or else it makes another data/backup folder inside the directory this script is stored in (01_prep_inputs)
  update_utm = TRUE,
  update_site_id = FALSE,
  write_back_to_path = FALSE,
  return_object = TRUE,
  col_easting = "utm_easting",
  col_northing = "utm_northing"
) 
```
